{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Sequence, TextIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default\n",
    "\n",
    "from DS_2_2022_HW2_efficient_net import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height, width and number of channels\n",
    "H: int = 224\n",
    "W: int = 224\n",
    "C: int = 3\n",
    "LABELS: int = 34\n",
    "    \n",
    "# Declare functions\n",
    "def parse(example) -> Dict[str, tf.Tensor]:\n",
    "    example = tf.io.parse_single_example(example, {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"mask\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64)})\n",
    "    example[\"image\"] = tf.image.convert_image_dtype(tf.image.decode_jpeg(example[\"image\"], channels=3), tf.float32)\n",
    "    example[\"mask\"] = tf.image.convert_image_dtype(tf.image.decode_png(example[\"mask\"], channels=1), tf.float32)\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and model\n",
    "download()\n",
    "\n",
    "# Load data. Train & Dev datasets are stored as tfrecord objects (see https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset)-\n",
    "# Test dataset is stored as pickled list.\n",
    "train = tf.data.TFRecordDataset(\"data/hw2_trainsample.tfrecord\")\n",
    "dev = tf.data.TFRecordDataset(\"data/hw2_devsample.tfrecord\")\n",
    "\n",
    "# TODO: Apply parse function declared above as an element of data pipeline on both train and dev so that jpeg pictures are decoded.\n",
    "train = ...\n",
    "dev = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "Continue by initializing EfficientNet, building the model, augmentation and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: for constructor of EfficientNet, you need to specify several parameters:\n",
    "# - width_coefficient, depth_coefficient: determine the scale for depth and width of the network. Reasonable to start with both equal to 1.0\n",
    "# - default_resolution: resolution of an input image\n",
    "# - dropout_rate: dropout rate used throughout the network\n",
    "# - include_top: if True then the network will include the final classification layer and produce a prediction for 1000 classes in ImageNet classification dataset,\n",
    "# if False, the network will return image features (the result of the last global average pooling)\n",
    "# weights: path to the file for pre-trained weights. Use 'efficientnet.h5' that you have downloaded in the zip file\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Load test dataset, predict labels and store results. Note that (for educational purposes) we load the data from pickled list. Therefore, transformation to Tensorflow dataset has to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "with open('hw2_outofsample.pickle', 'rb') as handle:\n",
    "    test = pickle.load(handle)\n",
    "\n",
    "# Produce dataset from list\n",
    "test = tf.data.Dataset.from_tensor_slices(test)\n",
    "\n",
    "# Predict\n",
    "test_prediction_prob = model.predict(test)\n",
    "test_prediction = [\n",
    "    np.argmax(probs) for probs in test_prediction_prob\n",
    "]\n",
    "\n",
    "# Store results\n",
    "pd.DataFrame({'prediction': test_prediction}).to_csv('data/hw2_outofsample_prediction.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
