{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import sample\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:      80000\n",
      "Number of columns:   196\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/hw1_devsample.csv', sep = ',', encoding = 'utf-8', low_memory=False, index_col='SK_ID_CURR')\n",
    "print(f'Number of rows:      {data.shape[0]}')\n",
    "print(f'Number of columns:   {data.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:      20000\n",
      "Number of columns:   195\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv('data/hw1_outofsample.csv', sep = ',', encoding = 'utf-8', low_memory=False, index_col='SK_ID_CURR')\n",
    "print(f'Number of rows:      {data_test.shape[0]}')\n",
    "print(f'Number of columns:   {data_test.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'TARGET'\n",
    "\n",
    "technical_columns = [\n",
    "    'SK_ID_CURR',\n",
    "    'TARGET',\n",
    "    'TIME',\n",
    "    'BASE',\n",
    "    'DAY',\n",
    "    'MONTH'\n",
    "]\n",
    "\n",
    "predictors = [col for col in data.columns if col not in technical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(dt, predictor, target, alpha = 0.01):\n",
    "\n",
    "    total_count = len(dt)\n",
    "    total_default_rate = np.mean(dt[target])\n",
    "    \n",
    "    data_group = dt.groupby(predictor).agg(\n",
    "        category_default_rate = (target, np.mean),\n",
    "        category_count = (target, len)\n",
    "    )\n",
    "    \n",
    "    data_group['category_frequency'] = data_group['category_count'] / total_count\n",
    "    data_group['category_encoding'] = (data_group['category_frequency'] * data_group['category_default_rate'] + alpha * total_default_rate) / (data_group['category_frequency'] + alpha)\n",
    "    \n",
    "    vector = dt[predictor]\n",
    "    encoding = {}\n",
    "    for value in vector.dropna().unique():\n",
    "        if value in data_group.index:\n",
    "            vector = vector.replace(value, data_group.loc[value][\"category_encoding\"])\n",
    "            encoding[value] = data_group.loc[value][\"category_encoding\"]\n",
    "        else:\n",
    "            vector = vector.replace(value, total_default_rate)\n",
    "            encoding[value] = total_default_rate\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {}\n",
    "for col in predictors:\n",
    "    if data[col].dtype == 'O':\n",
    "        encoding[col] = mean_target_encoding(data, col, target, alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, encoder in encoding.items():\n",
    "    data[col] = data[col].replace(encoder)\n",
    "    data_test[col] = data_test[col].replace(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data and infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[predictors] = data[predictors].fillna(data[predictors].mean())\n",
    "data_test[predictors] = data_test[predictors].fillna(data_test[predictors].mean())\n",
    "\n",
    "data = data.replace(np.inf, 99999999)\n",
    "data_test = data_test.replace(np.inf, 99999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level Maternity leave was not in dev data, therefore mean target is not computed\n",
    "data_test.loc[data_test['NAME_INCOME_TYPE']=='Maternity leave', 'NAME_INCOME_TYPE'] = data[target].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split data into data_dev and data_train. data_dev will be for computation of gini\n",
    "data_train, data_dev = train_test_split(\n",
    "    data, test_size=0.15, random_state=42, stratify = data[target]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare hyperparameters\n",
    "random.seed(17)\n",
    "criterion = \"gini\"\n",
    "splitter = \"best\"\n",
    "data_fraction = 0.8\n",
    "predictor_fraction = 0.8\n",
    "n_trees = 10\n",
    "max_depth=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for tree n. 1: 0.6986\n",
      "AUC for tree n. 2: 0.6255\n",
      "AUC for tree n. 3: 0.6707\n",
      "AUC for tree n. 4: 0.6922\n",
      "AUC for tree n. 5: 0.6030\n",
      "AUC for tree n. 6: 0.6874\n",
      "AUC for tree n. 7: 0.7025\n",
      "AUC for tree n. 8: 0.6939\n",
      "AUC for tree n. 9: 0.6534\n",
      "AUC for tree n. 10: 0.6983\n",
      "AUC for ensemble: 0.7357\n"
     ]
    }
   ],
   "source": [
    "# We compute prediction iteratively, we start with 0\n",
    "data_train['prediction'] = 0\n",
    "data_dev['prediction'] = 0\n",
    "data_test['prediction'] = 0\n",
    "\n",
    "data_train['sample_weight'] = 1 # sample_weight parameter for training, we start with equal weights\n",
    "auc_sum = 0 # sum of AUC coef. of all trees (used for convex combination), we can use AUC or GINI with the same results as one is obtained from the other as a linear trans.\n",
    "\n",
    "for n in range(n_trees):\n",
    "    \n",
    "    # Subsample predictors and data (we keep row indices)\n",
    "    data_iter = np.random.choice(data_train.index, round(data_train.shape[0]*data_fraction), replace=False)\n",
    "    pred_iter = np.random.choice(predictors, round(len(predictors)*predictor_fraction))\n",
    "    \n",
    "    # Train single tree\n",
    "    model = DecisionTreeClassifier(\n",
    "        random_state=n,\n",
    "        criterion=criterion,\n",
    "        splitter=splitter,\n",
    "        max_depth=max_depth,\n",
    "    )\n",
    "    clf = model.fit(\n",
    "        data_train.loc[data_iter, pred_iter],\n",
    "        data_train.loc[data_iter, target],\n",
    "        sample_weight=data_train.loc[data_iter, 'sample_weight'],\n",
    "    )\n",
    "    \n",
    "    # Compute prediction using single tree\n",
    "    data_train['prediction_single'] = clf.predict_proba(data_train[pred_iter])[:, 1]\n",
    "    data_dev['prediction_single'] = clf.predict_proba(data_dev[pred_iter])[:, 1]\n",
    "    data_test['prediction_single'] = clf.predict_proba(data_test[pred_iter])[:, 1]\n",
    "    \n",
    "    # Evaluate AUC\n",
    "    auc = roc_auc_score(data_dev[target], data_dev['prediction_single'])\n",
    "    print(f'AUC for tree n. {n+1}: {auc :.4f}')\n",
    "    \n",
    "    # Update prediction as a convex combination of all trees\n",
    "    data_train['prediction'] = (auc_sum*data_train['prediction']+auc*data_train['prediction_single'])/(auc_sum+auc)\n",
    "    data_dev['prediction'] = (auc_sum*data_dev['prediction']+auc*data_dev['prediction_single'])/(auc_sum+auc)\n",
    "    data_test['prediction'] = (auc_sum*data_test['prediction']+auc*data_test['prediction_single'])/(auc_sum+auc)\n",
    "    auc_sum += auc\n",
    "    \n",
    "    # Updata sample_weight\n",
    "    data_train['sample_weight'] = abs(data_train['prediction']-data_train[target])\n",
    "    \n",
    "    \n",
    "# Evaluate AUC for ensemble  \n",
    "auc_ensemble = roc_auc_score(data_dev[target], data_dev['prediction'])\n",
    "print(f'AUC for ensemble: {auc_ensemble :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[['prediction']].to_csv('test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
